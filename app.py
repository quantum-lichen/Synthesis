import streamlit as st
import plotly.express as px
import plotly.graph_objects as go
import pandas as pd
from io import BytesIO
from fpdf import FPDF
import numpy as np
from collections import Counter, defaultdict
import re
from sklearn.feature_extraction.text import TfidfVectorizer
from sklearn.metrics.pairwise import cosine_similarity

# Configuration de la page
st.set_page_config(
    page_title="Nordique Analyzer",
    page_icon="üß†",
    layout="wide"
)

def extract_pdf_text(file):
    """Extrait le texte d'un fichier PDF"""
    try:
        import PyPDF2
        pdf_reader = PyPDF2.PdfReader(BytesIO(file.read()))
        text = ""
        for page in pdf_reader.pages:
            text += page.extract_text()
        return text
    except Exception as e:
        st.error(f"Erreur lors de la lecture du PDF: {str(e)}")
        return ""

def extract_sentences(text):
    """Extrait les phrases d'un texte"""
    # Nettoyage basique
    text = re.sub(r'\s+', ' ', text).strip()
    # D√©coupage en phrases
    sentences = re.split(r'[.!?]+', text)
    sentences = [s.strip() for s in sentences if len(s.strip()) > 20]
    return sentences

def calculate_similarity_matrix(documents):
    """Calcule la matrice de similarit√© entre documents"""
    if len(documents) < 2:
        return None
    
    vectorizer = TfidfVectorizer(max_features=100, stop_words='english')
    try:
        tfidf_matrix = vectorizer.fit_transform(documents)
        similarity_matrix = cosine_similarity(tfidf_matrix)
        return similarity_matrix
    except:
        return None

def analyze_documents(documents):
    """Analyse les consensus et discordances entre documents"""
    
    # Extraire toutes les phrases de tous les documents
    all_sentences_by_doc = []
    for doc in documents:
        sentences = extract_sentences(doc)
        all_sentences_by_doc.append(sentences)
    
    # Aplatir toutes les phrases
    all_sentences = []
    sentence_to_doc = []
    for doc_idx, sentences in enumerate(all_sentences_by_doc):
        for sentence in sentences:
            all_sentences.append(sentence)
            sentence_to_doc.append(doc_idx)
    
    if len(all_sentences) < 2:
        return None
    
    # Calculer les similarit√©s entre phrases
    vectorizer = TfidfVectorizer(max_features=50, stop_words='english', min_df=1)
    try:
        tfidf_matrix = vectorizer.fit_transform(all_sentences)
    except:
        return {
            "consensus": {},
            "discordances": {},
            "statistics": {
                "total_docs": len(documents),
                "consensus_rate": 0,
                "avg_similarity": 0
            },
            "similarity_matrix": None
        }
    
    similarity_matrix = cosine_similarity(tfidf_matrix)
    
    # Identifier les phrases consensuelles (similaires dans plusieurs documents)
    consensus_phrases = []
    discordance_phrases = []
    
    analyzed_phrases = set()
    
    for i, sentence in enumerate(all_sentences):
        if sentence in analyzed_phrases:
            continue
        
        doc_i = sentence_to_doc[i]
        
        # Trouver les phrases similaires dans d'autres documents
        similar_docs = set()
        similarity_scores = []
        
        for j, other_sentence in enumerate(all_sentences):
            if i != j:
                doc_j = sentence_to_doc[j]
                sim_score = similarity_matrix[i][j]
                
                if sim_score > 0.3 and doc_i != doc_j:  # Seuil de similarit√©
                    similar_docs.add(doc_j)
                    similarity_scores.append(sim_score)
        
        if len(similar_docs) >= max(1, len(documents) // 2):  # Consensus
            consensus_phrases.append({
                "phrase": sentence,
                "support_docs": len(similar_docs) + 1,
                "avg_similarity": np.mean(similarity_scores) if similarity_scores else 0,
                "source_doc": doc_i
            })
            analyzed_phrases.add(sentence)
    
    # Calculer la similarit√© globale entre documents
    doc_similarity = calculate_similarity_matrix(documents)
    
    # Identifier les discordances (phrases uniques ou contradictoires)
    for doc_idx, sentences in enumerate(all_sentences_by_doc):
        for sentence in sentences[:3]:  # Prendre les premi√®res phrases de chaque doc
            if sentence not in analyzed_phrases:
                discordance_phrases.append({
                    "phrase": sentence,
                    "source_doc": doc_idx,
                    "uniqueness": 1.0
                })
    
    # Trier par pertinence
    consensus_phrases = sorted(consensus_phrases, key=lambda x: x["avg_similarity"], reverse=True)[:10]
    discordance_phrases = sorted(discordance_phrases, key=lambda x: x["uniqueness"], reverse=True)[:10]
    
    # Calculer les statistiques
    avg_similarity = np.mean(doc_similarity) if doc_similarity is not None else 0
    
    report = {
        "consensus": consensus_phrases,
        "discordances": discordance_phrases,
        "statistics": {
            "total_docs": len(documents),
            "consensus_rate": len(consensus_phrases) / max(1, len(consensus_phrases) + len(discordance_phrases)),
            "avg_similarity": float(avg_similarity)
        },
        "similarity_matrix": doc_similarity
    }
    
    return report

def plot_similarity_heatmap(similarity_matrix, num_docs):
    """Cr√©e une heatmap de similarit√© entre documents"""
    if similarity_matrix is None:
        return None
    
    labels = [f"Doc {i+1}" for i in range(num_docs)]
    
    fig = go.Figure(data=go.Heatmap(
        z=similarity_matrix,
        x=labels,
        y=labels,
        colorscale='RdYlGn',
        text=np.round(similarity_matrix, 2),
        texttemplate='%{text}',
        textfont={"size": 10},
        colorbar=dict(title="Similarit√©")
    ))
    
    fig.update_layout(
        title="Matrice de Similarit√© entre Documents",
        xaxis_title="Documents",
        yaxis_title="Documents",
        height=400
    )
    
    return fig

def plot_consensus_chart(report):
    """Cr√©e un graphique des consensus et discordances"""
    
    # Pr√©parer les donn√©es
    data = []
    
    for item in report["consensus"][:5]:
        data.append({
            "Phrase": item["phrase"][:50] + "...",
            "Support": item["support_docs"],
            "Type": "Consensus"
        })
    
    for item in report["discordances"][:5]:
        data.append({
            "Phrase": item["phrase"][:50] + "...",
            "Support": 1,
            "Type": "Discordance"
        })
    
    if not data:
        return None
    
    df = pd.DataFrame(data)
    
    fig = px.bar(
        df,
        x="Support",
        y="Phrase",
        color="Type",
        orientation='h',
        title="Top 5 Consensus et Discordances",
        color_discrete_map={"Consensus": "#2ecc71", "Discordance": "#e74c3c"}
    )
    
    fig.update_layout(height=400, showlegend=True)
    
    return fig

def generate_pdf_report(report):
    """G√©n√®re un rapport PDF"""
    pdf = FPDF()
    pdf.add_page()
    
    # Titre
    pdf.set_font("Arial", 'B', 16)
    pdf.cell(0, 10, "Rapport d'Analyse - Consensus/Discordance", ln=True, align='C')
    pdf.ln(10)
    
    # Statistiques
    pdf.set_font("Arial", 'B', 12)
    pdf.cell(0, 10, "Statistiques Globales", ln=True)
    pdf.set_font("Arial", '', 10)
    pdf.cell(0, 8, f"Nombre de documents analyses: {report['statistics']['total_docs']}", ln=True)
    pdf.cell(0, 8, f"Taux de consensus: {report['statistics']['consensus_rate']*100:.1f}%", ln=True)
    pdf.cell(0, 8, f"Similarite moyenne: {report['statistics']['avg_similarity']*100:.1f}%", ln=True)
    pdf.ln(10)
    
    # Consensus
    pdf.set_font("Arial", 'B', 12)
    pdf.cell(0, 10, "Points de Consensus", ln=True)
    pdf.set_font("Arial", '', 9)
    
    for idx, item in enumerate(report["consensus"][:5], 1):
        phrase = item["phrase"][:80].encode('latin-1', 'replace').decode('latin-1')
        pdf.multi_cell(0, 6, f"{idx}. {phrase} (Support: {item['support_docs']} docs)")
        pdf.ln(2)
    
    pdf.ln(5)
    
    # Discordances
    pdf.set_font("Arial", 'B', 12)
    pdf.cell(0, 10, "Points de Discordance", ln=True)
    pdf.set_font("Arial", '', 9)
    
    for idx, item in enumerate(report["discordances"][:5], 1):
        phrase = item["phrase"][:80].encode('latin-1', 'replace').decode('latin-1')
        pdf.multi_cell(0, 6, f"{idx}. {phrase}")
        pdf.ln(2)
    
    # G√©n√©rer le PDF
    pdf_output = pdf.output(dest="S").encode("latin-1", errors='ignore')
    
    return pdf_output

def load_example_docs():
    """Charge des documents d'exemple"""
    example_docs = [
        """Le r√©chauffement climatique est une r√©alit√© scientifique ind√©niable. 
        Les temp√©ratures moyennes mondiales ont augment√© de plus de 1¬∞C depuis l'√®re pr√©industrielle.
        Les √©nergies renouvelables sont essentielles pour r√©duire les √©missions de CO2.
        L'action climatique doit √™tre une priorit√© pour tous les gouvernements.""",
        
        """Le changement climatique repr√©sente un d√©fi majeur pour l'humanit√©.
        Les √©missions de gaz √† effet de serre doivent √™tre r√©duites rapidement.
        Les √©nergies renouvelables comme le solaire et l'√©olien sont des solutions viables.
        La transition √©nerg√©tique n√©cessite des investissements massifs.""",
        
        """Certains contestent l'urgence du r√©chauffement climatique.
        Les co√ªts de la transition √©nerg√©tique sont trop √©lev√©s pour l'√©conomie.
        Les √©nergies fossiles restent n√©cessaires pour maintenir la croissance √©conomique.
        Les mod√®les climatiques sont incertains et parfois contradictoires.""",
        
        """L'innovation technologique peut r√©soudre la crise climatique.
        Les √©nergies renouvelables deviennent de plus en plus comp√©titives.
        La collaboration internationale est cruciale pour lutter contre le changement climatique.
        Les entreprises doivent adopter des pratiques durables."""
    ]
    return example_docs

def main():
    # En-t√™te
    st.title("üß† Nordique Analyzer")
    st.markdown("### Analyse de Consensus et Discordances entre Documents")
    st.markdown("---")
    
    # Instructions
    with st.expander("‚ÑπÔ∏è Comment utiliser cette application"):
        st.write("""
        1. **Uploadez vos documents** (TXT ou PDF) ou essayez l'exemple
        2. **Cliquez sur Analyser** pour lancer l'analyse
        3. **Consultez les r√©sultats** : consensus, discordances, et visualisations
        4. **T√©l√©chargez le rapport** en PDF si besoin
        """)
    
    # Colonnes pour les boutons
    col1, col2 = st.columns([3, 1])
    
    with col1:
        uploaded_files = st.file_uploader(
            "üìÅ Choisissez vos fichiers (TXT ou PDF)",
            type=["txt", "pdf"],
            accept_multiple_files=True
        )
    
    with col2:
        use_example = st.button("üéØ Essayer un exemple", use_container_width=True)
    
    # Bouton d'analyse
    analyze_button = st.button("üîç Analyser les Documents", type="primary", use_container_width=True)
    
    # Logique d'analyse
    documents = []
    
    if use_example:
        documents = load_example_docs()
        st.success(f"‚úÖ {len(documents)} documents d'exemple charg√©s!")
    
    elif analyze_button and uploaded_files:
        with st.spinner("üìñ Lecture des documents..."):
            for uploaded_file in uploaded_files:
                if uploaded_file.type == "application/pdf":
                    text = extract_pdf_text(uploaded_file)
                else:
                    text = uploaded_file.read().decode("utf-8", errors='ignore')
                
                if text:
                    documents.append(text)
        
        st.success(f"‚úÖ {len(documents)} documents charg√©s!")
    
    elif analyze_button and not uploaded_files:
        st.warning("‚ö†Ô∏è Veuillez d'abord uploader des fichiers ou essayer l'exemple!")
    
    # Analyser les documents
    if documents:
        with st.spinner("üî¨ Analyse en cours..."):
            report = analyze_documents(documents)
        
        if report is None:
            st.error("‚ùå Erreur lors de l'analyse. V√©rifiez vos documents.")
            return
        
        st.markdown("---")
        st.markdown("## üìä R√©sultats de l'Analyse")
        
        # Statistiques globales
        col1, col2, col3 = st.columns(3)
        
        with col1:
            st.metric(
                "üìö Documents Analys√©s",
                report['statistics']['total_docs']
            )
        
        with col2:
            st.metric(
                "ü§ù Taux de Consensus",
                f"{report['statistics']['consensus_rate']*100:.1f}%"
            )
        
        with col3:
            st.metric(
                "üìà Similarit√© Moyenne",
                f"{report['statistics']['avg_similarity']*100:.1f}%"
            )
        
        st.markdown("---")
        
        # Visualisations
        col1, col2 = st.columns(2)
        
        with col1:
            st.markdown("### üìä Consensus vs Discordances")
            chart = plot_consensus_chart(report)
            if chart:
                st.plotly_chart(chart, use_container_width=True)
        
        with col2:
            st.markdown("### üî• Matrice de Similarit√©")
            heatmap = plot_similarity_heatmap(
                report['similarity_matrix'],
                report['statistics']['total_docs']
            )
            if heatmap:
                st.plotly_chart(heatmap, use_container_width=True)
        
        st.markdown("---")
        
        # D√©tails des r√©sultats
        tab1, tab2 = st.tabs(["‚úÖ Points de Consensus", "‚ö†Ô∏è Points de Discordance"])
        
        with tab1:
            st.markdown("### Points de Consensus Identifi√©s")
            if report["consensus"]:
                for idx, item in enumerate(report["consensus"], 1):
                    with st.container():
                        st.markdown(f"**{idx}.** {item['phrase']}")
                        st.caption(f"üîπ Support: {item['support_docs']} documents | Similarit√©: {item['avg_similarity']:.2%}")
                        st.markdown("---")
            else:
                st.info("Aucun consensus significatif d√©tect√©.")
        
        with tab2:
            st.markdown("### Points de Discordance Identifi√©s")
            if report["discordances"]:
                for idx, item in enumerate(report["discordances"], 1):
                    with st.container():
                        st.markdown(f"**{idx}.** {item['phrase']}")
                        st.caption(f"üî∏ Document source: {item['source_doc'] + 1}")
                        st.markdown("---")
            else:
                st.info("Aucune discordance majeure d√©tect√©e.")
        
        # Bouton de t√©l√©chargement PDF
        st.markdown("---")
        st.markdown("### üì• T√©l√©charger le Rapport")
        
        pdf_output = generate_pdf_report(report)
        
        st.download_button(
            label="üìÑ T√©l√©charger le Rapport PDF",
            data=pdf_output,
            file_name="rapport_consensus_discordance.pdf",
            mime="application/pdf",
            use_container_width=True
        )
    
    # Footer
    st.markdown("---")
    st.markdown(
        "<div style='text-align: center; color: gray;'>"
        "Nordique Analyzer v1.0 | Analyse intelligente de documents"
        "</div>",
        unsafe_allow_html=True
    )

if __name__ == "__main__":
    main()
